<!DOCTYPE html>
<html>
    

<head>

    <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  As we have seen from my previous post.
The probability vector of
a deterministic network cannot consistently capture the uncertainty of its
prediction. And we have also seen that if we use the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics and using it to study the model uncertainty. Then we will use 
this uncertainty to design an active learning query strategy.


" />
    <meta property="og:description" content="
  As we have seen from my previous post.
The probability vector of
a deterministic network cannot consistently capture the uncertainty of its
prediction. And we have also seen that if we use the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics and using it to study the model uncertainty. Then we will use 
this uncertainty to design an active learning query strategy.


" />
    
    <meta name="author" content="Stream of Conscious" />

    
    <meta property="og:title" content="Overview of Bayesian deep learning" />
    <meta property="twitter:title" content="Overview of Bayesian deep learning" />
    


<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
    }
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



<link rel="stylesheet" type="text/css" href="/style.css" />
<link rel="alternate" type="application/rss+xml" title="Stream of Conscious - " href="/feed.xml" />


    








<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-8161570-6', 'auto');
    ga('send', 'pageview');
</script>

<!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
</head>


  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Stream of Conscious</a></h1>
            <p class="site-description"></p>
          </div>

          <nav>
              <a href="/about"> About </a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Overview of Bayesian deep learning</h1>
    <p class="post-meta">

      <time datetime="2020-05-14T00:00:00-07:00" itemprop="datePublished">
        
        May 14, 2020
      </time>

      <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        by <span itemprop="name">Hongshan Li</span>
      </span>
        
      <span>[
      
        
        <a href="/tag/Bayesian-deep-learning"><code class="highligher-rouge"><nobr>Bayesian-deep-learning</nobr></code>&nbsp;</a>
  
    ]</span>

      <!--
      <span class="share-buttons">
        <span class="share-button"><a class="twitter-share-button" href="https://twitter.com/share" data-show-count="false">Tweet</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></span>

        <span class="share-button"><span class="fb-like" data-href="/bayesian-deep-learning/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="false" data-share="true"></span></span>
      </span>
      <div style="clear: both;"/>
      -->

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <blockquote>
  <p>As we have seen from my <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a>.
The probability vector of
a deterministic network cannot consistently capture the uncertainty of its
prediction. And we have also seen that if we use the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics and using it to study the model uncertainty. Then we will use 
this uncertainty to design an active learning query strategy.</p>
</blockquote>

<!--more-->

<h2 id="warm-up">Warm up</h2>
<p>In supervised machine learning, the objective is to find a function
$f$ that best describes the relation between
the  features $X = (x_1, x_2, \cdots, x_n)$
and the labels $Y = (y_1, y_2, \cdots, y_n)$. Suppose the data 
$D = (X, Y)$ is observed from the system $S$. Then, $f$ is a proxy
to the real data generation process of $S$ which is difficult to know.
The criterion for a good model $f$ is that when new observations 
$D^{\prime} = (X^{\prime}, Y^{\prime})$ arises, $f$ can still relate
$X^{\prime}$ to $Y^{\prime}$ with good precision.</p>

<p>Let’s take one step back and think about what are we doing when building
and training an ML model?
There are infinitely many ways you can relate $X$ to $Y$ up to certain extent, 
the process of building and training an ML model is amount to find an $f$
such that <em>after</em> seeing the data $D$, we belief $f$ is the most likely 
candidate that describes the unknown data generation process of $S$.</p>

<p>Formally, let $\Theta$ be the function space that describes the process of 
$S$ that relates $X$ to $Y$, i.e. $\Theta$ is a set of all <em>possible</em> candidates
$\theta$ that relates $X$ to $Y$. The process of machine learning is to 
find a conditional distribution $p(\theta | D)$ over $\Theta$. This distribution
reflects our belief on how likely the candidate $\theta$ is the one that relates
$X$ to $Y$. This distribution $p(\theta | D)$ has an interesting name, it is called
the <em>posterior</em> distribution on $\Theta$, because it is something we derive <em>after</em>
seeing $D$.</p>

<p>This brings us to the playground of Bayesian statistics, because it offers a 
framework for us to think about $p(\theta | D)$.</p>

<h2 id="bayes-theorem">Bayes’ Theorem</h2>
<p>There are two things you can do when you are handed with the data $D$:</p>

<p>1) Based on your understanding of the $S$, you make a hypothesis $H$ about the 
how $X$ and $Y$ are related, then you update your hypothesis $H$ after
inspecting $D$</p>

<p>2) You can compute frequency statistics on $D$ and make claims on $S$ 
directly from those frequency statistics. For example, you might have
heard people talking about making <em>Null Hypothesis</em> and calculating
$p$-value that reflects the probability that <strong>given</strong> Null Hypothesis
is true, it would be rejected $p*100$ times out of 100 trials 
due to randomness in data collection.</p>

<p>If you prefer 1, then you are labeled as a <em>Bayesian</em>
If you prefer 2, then you are labeled as a <em>frequentist</em></p>

<p>The difference between Bayesians and frequentists is that 
Bayesians want $P(H | D)$ whereas frequentists want $P(D | H)$, i.e.
Bayesians want to know how much belief to put in the hypothesis 
$H$ after seeing the data $D$; frequentists want to know given the 
hypothesis is true, what’s the odd for the observation $D$?</p>

<p>One thing that relates these two schools of thought is the Bayes’ Theorem:</p>

\[P(H | D) = \frac{P(D | H) P(H)}{P(D)}\]

<p>In Bayesian statistics, each term above has a name:</p>

<p>$P(D | H)$ is the <em>likelyhood</em> of the dataset $D$,i.e.
how likely can we see $D$ given hypothesis $H$</p>

<p>$P(H)$ is the <em>prior</em> on the hypothesis $H$,i.e. how
deep we believe the data generation process is $H$.</p>

<p>$P(D)$ is called the <em>evidence</em>. It is the probablity of the 
observation $D$. One way to think about it is “the average” 
probability of seeing the observation $D$ over all hypothesis
of data generation process:</p>

\[P(D) = \int P(D | H) P(H) dH\]

<p>If you do machine learning, then you are baptized by Bayesian
school of thought, even if you have not heard of Bayesian statistics
until 10 mins ago. For example, when you do the following things</p>

<figure class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code></pre></figure>

<p>you are defining $\Theta$ as the set such that each of its member looks like
a two-layer neuron network with ReLU activation. The prior distribution 
you put on $\Theta$ is the joint distribution you put on each neuron. 
If you believe each neuron follows a Gaussian distribution
with mean 0 and standard deviation 1, then the prior on $\Theta$ is the joint
distribution of $10\times 128 \times 2$ Gaussians with mean 0 and standard 
deviation 1.</p>

<p>When you train your model, you are updating your posterior $P(\theta | D)$ on 
$\Theta$. Each “fit” you do gives you the most likely candidate $\theta$ given $D$.</p>

<h2 id="uncertainty">Uncertainty</h2>
<p>Before we jump into uncertainty in machine learning, let’s ask ourselves what are
we even uncertain about?</p>

<p>I think one reasonable thing to be uncertain about is the posterior distribution
$p(\theta | D)$ on $\Theta$. We find a posterior through machine learning 
(aka maximum likelyhood),
how do we know how far it is from the true posterior?</p>

<p>You can “compute” this uncertainty via Shannon entropy:</p>

\[H[\theta | D] = -\int_{\Theta} p(\theta | D) \log p(\theta | D) d\theta\]

<p>The uncertainty on the posterior $p(\theta | D)$ naturally carries over 
to the uncertainty for making predictions. Let $x^*$ be a new sample
observed from the system $S$.</p>

<p>Given our function space $\Theta$ and 
posterior $p(\theta | D)$, the probability of $x^*$ mapped to $y^*=c$
under the unknown data generation process of $S$ is given by</p>

\[p(y^* | x^*, D) = \int_{\Theta} p(y^* | x^*, \theta)p(\theta | D) d\theta\]

<p>If the output $y^*$ is a discrete random variable that takes on value
$c_1, c_2, \cdots, c_n$, then we can again use Shannon entropy to 
“compute” this predictive uncertainty</p>

\[H[y^*|x^*, D] = - \sum_{i=1}^n p(y^*=c_i | x^*, D)\log p(y^*=c_i | x^*, D)\]

<h2 id="information-theoretic-active-learning">Information-theoretic active learning</h2>
<p>The goal of active learning is to selectively add data to the training 
set $D$ that “boost the model’s performance to the largest extent”. 
In light of the Bayesian philosophy, how do we materialize the objective of 
active learning?</p>

<p>One reasonable thing we can do is to enlarge the data set $D$ in the way
so that it reduces the uncertainty of posterior $p(\theta | D)$ fastest.
We assumed the existence of a function space $\Theta$ that gathers all potential
candidates for describing the data generation process of $S$, we have computed
the posterior $p(\theta | D)$ on $\Theta$. Now, we are given more data $D^{\prime}$
we can say the most valuable sample $(x’, y’)$ is the one that reduces the 
uncertainty of the posterior $p(\theta | D \cup {(x’, y’)})$ fastest, i.e.</p>

\[\tag{1}
\text{arg max}_{(x',y')} H[\theta | D] - \mathbb{E}_{y'\sim p(y'|x',D)}
    (H[\theta | D'\cup {(x', y')}])\]

<p>Of course, in practice there is no way you can evalute the above quantity,
because it involves many intractable integrals. 
But if $y$ is a discrete random variable, i.e. classification ML problem, 
there are ways to get around it. Instead of looking at the posterior uncertainty,
we can look at the predictive uncertainty because $H[y^*|x^*, D]$ is computed
as a finite sum.</p>

<p>In this case, the sample $(x’, y’)$ satisfies equation (1) is also the one
that has the biggest conditional information gain:</p>

\[\tag{2}
I[\theta, y'|x', D] = \text{arg max}_{(x', y')} H[y'|x',D] -
    \mathbb{E}_{\theta \sim p(\theta | D)}[H[y'|x', \theta]]\]

<p>We can interpret the samples $(x’, y’)$ with maximal conditional information
gain as the one such that the overall predictive uncertainty is high (high 
$H[y|x, D]$), but for each fixed element $\theta$ in $\Theta$, the 
predictive entropy is low (low $H[y|x, \theta]$). Those are the samples
that incurs biggest dissagreement among individual members of $\Theta$.</p>

<p>The query strategy defined by eq (2) is called Bayesian Active Learning by
Disagreement (BALD)</p>

<p>In the next blog, I will discuss practical implementation of BALD via
approximate inference.</p>

<h2 id="reference">Reference</h2>

<p><a href="https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf">Bayesians vs Frequentists</a></p>

<p><a href="http://mlg.eng.cam.ac.uk/yarin/thesis/3_bayesian_deep_learning.pdf">Uncertainty in Deep Learning (Yarin Gal’s Thesis)</a></p>

<p><a href="https://arxiv.org/pdf/1703.02910.pdf">Deep Bayesian Active Learning with Image Data</a></p>

<p><a href="https://arxiv.org/pdf/1112.5745.pdf">Bayesian Active Learning for Classification and Preference Learning</a></p>


  </div>


  <div class="page-navigation">
    
      <a class="prev" href="/knapsack/">&larr; Knapsack problem</a>
    

    
      <a class="next" href="/DRL-lit-review/">Not-So-formal Lit Review of Recent Progress in Deep Reinforcement Learning &rarr;</a>
    
  </div>

  
    

  

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          <!--   
<div style="clear: both;"/>
<footer class="site-footer">
    <p>
    Add stuff to footer
    </p>
</footer>
 -->
        </footer>
      </div>
    </div>
  </body>
</html>
