<!DOCTYPE html>
<html>
    

<head>

    <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="">
    <meta property="og:description" content="" />
    
    <meta name="author" content="Stream of Conscious" />

    


<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
    }
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



<link rel="stylesheet" type="text/css" href="/style.css" />
<link rel="alternate" type="application/rss+xml" title="Stream of Conscious - " href="/feed.xml" />


    








<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-8161570-6', 'auto');
    ga('send', 'pageview');
</script>

<!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
</head>


  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Stream of Conscious</a></h1>
            <p class="site-description"></p>
          </div>

          <nav>
              <a href="/about"> About </a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <div class="posts">
  
    <article class="post">
     <li>
         
         <span>
             May 21, 2020
         </span>

         <span>[
             
        ]</span>
     </li>

      <h1><a href="/example/">Notes from Yarin Gal's Thesis</a></h1>

      <div class="entry">
        <h2 id="techniques-to-estimate-the-expected-log-likelihood">Techniques to estimate the expected log likelihood</h2>

<script type="math/tex; mode=display">\int q_{\theta} \log p(y_i | f^w(x_i)) dw</script>

<h3 id="monte-carlo-estimator-in-variational-inference">Monte Carlo Estimator in variational inference</h3>

<p>We wish to estimate the derivatives of the expected
log likelihood with respect to $\theta$. This allows
us to optimize the objective for the variational inference.</p>

<p>Consider in general</p>

<script type="math/tex; mode=display">I(\theta) = \frac{\partial}{\partial\theta}
\int f(x) p_{\theta}(x) dx</script>

<h4 id="the-score-function-estimator">The score function estimator</h4>
<p>Assume we can do differentiating outside integral side</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial}{\partial\theta}
\int f(x) p_{\theta}(x) dx & = 
\int f(x) \frac{\partial}{\partial\theta} p_{\theta}(x) dx \\
& \int f(x) \frac{\partial \log p_{\theta}(x)}{\partial\theta} 
p_{\theta}(x) dx
\end{align} %]]></script>

<p>This leads to an unbiased stochastic estimator</p>

<script type="math/tex; mode=display">\hat{I}_1(\theta) = f(x)\frac{\partial \log p_{\theta}(x)}{\partial\theta}</script>

<p>with $x \sim p_{\theta}(x)$, i.e. sample a few $x$ from 
$p_{\theta}(x)$, we can use it to estimate $I(\theta)$</p>

<h2 id="stochastic-regularizer">Stochastic Regularizer</h2>

<h3 id="dropout-and-approximate-inference">Dropout and Approximate Inference</h3>

<p>To use the pathwise derivative estimator, we need to reparametrize each 
$q_{\theta_{l, i}}(w_{l,i})$ (The family of distributions on $w_{l, i}$
paramterized by $\theta_{l, i}$) as $w_{l,i} = g(\theta_{l,i}, \epsilon_{l,i})$
and specify some $p(\epsilon_{l,i})$.</p>

<p>The loss objective of variational inference is</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat{L}_{VI}(\theta) & = - C \sum_{i\in S} 
\int q_{\theta}(w) \log p(y_i | f^w(x_i)) dw + KL(q_{\theta}(w) || p(w))  \\
& = -C \sum_{i\in S} 
\int p(\epsilon)\log p(y_i|f^{g(\theta, \epsilon)}(x_i))d\epsilon 
+ KL(q_{\theta}(w) || p(w))
\end{align} %]]></script>

<p>Then we can replace the expected log likelihood with its stochastic 
estimator</p>

<script type="math/tex; mode=display">\hat{L}_{MC}(\theta) = -C \sum_{i \in S} \log p(y_i|f^{g(\theta,\epsilon)}(x_i)) 
+ KL(q_{\theta}(w) || p(w))</script>

<p>such that $\mathbb{E}<em>{S, \epsilon}(\hat{L}</em>{MC}(\theta)) = \hat{L}_{VI}(\theta)$</p>

<p>Therefore the SGD algorithm for minimizing $q_{\theta}(w)$ and $p(w|X, Y)$
is</p>

<p>If weights are trained with probability $p$, i.e. each weight has a 
probability $p$ to be turned on. Then, in the test time, we want
expected output of all those “thined network” therefore, we need to 
multiply each weights by $p$.</p>

<p>Optimising any neural network with dropout is equivalent to a form
of approximate inference in a probabilistic interpretation of the 
model.</p>

<h2 id="reference">Reference</h2>
<p><a href="https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks.pdf">Grave, 2011, Practical Variational Inference for Neural Network</a></p>


      </div>

      <a href="/example/" class="read-more">Read More</a>
    </article>
  
    <article class="post">
     <li>
         
         <span>
             May 14, 2020
         </span>

         <span>[
             
             
             <a class="post-tag" href="/tag/Bayesian-deep-learning">
                 <nobr>Bayesian-deep-learning</nobr>&nbsp;</a>
             
        ]</span>
     </li>

      <h1><a href="/bayesian-deep-learning/">Overview of Bayesian deep learning</a></h1>

      <div class="entry">
        <blockquote>
  <p>As we have seen from my <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a>.
The probability vector of
a deterministic network cannot consistently capture the uncertainty of its
prediction. And we have also seen that if we use the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics and using it to study the model uncertainty. Then we will use 
this uncertainty to design an active learning query strategy.</p>
</blockquote>


      </div>

      <a href="/bayesian-deep-learning/" class="read-more">Read More</a>
    </article>
  
    <article class="post">
     <li>
         
         <span>
             Apr 11, 2020
         </span>

         <span>[
             
             
             <a class="post-tag" href="/tag/Algorithms">
                 <nobr>Algorithms</nobr>&nbsp;</a>
             
        ]</span>
     </li>

      <h1><a href="/knapsack/">Knapsack problem</a></h1>

      <div class="entry">
        <blockquote>
  <p>Given a list of positive integers 
$(x_0,…,x_n)$ and a positive integer $m$, how many non-negative integer tuples
$(v_0,…,v_n)$ are there so that</p>
</blockquote>

<script type="math/tex; mode=display">\sum v_i x_i = m</script>


      </div>

      <a href="/knapsack/" class="read-more">Read More</a>
    </article>
  
    <article class="post">
     <li>
         
         <span>
             Apr 8, 2020
         </span>

         <span>[
             
             
             <a class="post-tag" href="/tag/Deep-learning">
                 <nobr>Deep-learning</nobr>&nbsp;</a>
             
             
             <a class="post-tag" href="/tag/Bayesian-deep-learning">
                 <nobr>Bayesian-deep-learning</nobr>&nbsp;</a>
             
        ]</span>
     </li>

      <h1><a href="/uncertainty-of-deep-neural-network/">Uncertainty of Deep Neural Network</a></h1>

      <div class="entry">
        <blockquote>
  <p>A homo sapien learns its environment by investigating objects that it is uncertain
about. More successful homo sapiens are generally those who push themselves
outside their comfort zone and navigate through unfamiliar circumstances. 
Suppose deep learning models do in some sense mimic how human brain works, then can 
we use the success story of those donquixotic apes to train our models? 
In this post, let’s study the notion of model’s uncertainty and use it in our training
process</p>
</blockquote>


      </div>

      <a href="/uncertainty-of-deep-neural-network/" class="read-more">Read More</a>
    </article>
  
</div>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          <!--   
<div style="clear: both;"/>
<footer class="site-footer">
    <p>
    Add stuff to footer
    </p>
</footer>
 -->
        </footer>
      </div>
    </div>
  </body>
</html>
