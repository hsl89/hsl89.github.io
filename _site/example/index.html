<!DOCTYPE html>
<html>
    

<head>

    <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Central theme:
Optimizing any deterministic NN with dropout is equivalent to 
a form of approximate inference in a probabilistic interpretation
of the model. This means the optimal weights found through the optimization
of a dropout NN are the same as the optimal variational parameters
in a Bayesian NN with the same structure.

Why do we call the paramters in a Bayesian NN a variational parameter?

want to find $q(w)$ that is close to the model’s posterior $p(w|X, Y)$ 
what is $\theta$ in relation to the weight parameters to Bayesian NN?

Techniques to estimate the expected log likelihood



Monte Carlo Estimator in variational inference

We wish to estimate the derivatives of the expected
log likelihood with respect to $\theta$. This allows
us to optimize the objective for the variational inference.

Consider in general



The score function estimator
Assume we can do differentiating outside integral side



This leads to an unbiased stochastic estimator



with $x \sim p_{\theta}(x)$, i.e. sample a few $x$ from 
$p_{\theta}(x)$, we can use it to estimate $I(\theta)$

Stochastic Regularizer

Dropout and Approximate Inference

To use the pathwise derivative estimator, we need to reparametrize each 
$q_{\theta_{l, i}}(w_{l,i})$ (The family of distributions on $w_{l, i}$
paramterized by $\theta_{l, i}$) as $w_{l,i} = g(\theta_{l,i}, \epsilon_{l,i})$
and specify some $p(\epsilon_{l,i})$.

The loss objective of variational inference is



Then we can replace the expected log likelihood with its stochastic 
estimator



such that 


  
    
      Therefore the SGD algorithm for minimizing  and $$p(w
      X, Y)$$
    
  



  Given dataset X, Y
Define learning rate $\eta$
Initialize parameters $\theta$ randomly


While $\theta$ has not converged

  
    Sample $M$ random variables $\hat{\epsilon}\sim p(\epsilon)$, $S$ a random 
subset of ${1, \dots, N}$ of size $M$
Calculate Stochastic derivative estimator w.r.t. $\theta$:
  





  
    Update $\theta$:
  




Let’s take a look at its relation with some stochastic regularization techniques.
The most popular SRT is dropout Suppose each input feature is used with 
probability $p$. Suppose the model has $N$ parameters, then dropout produces
$2^N$ ‘thinned’ networks. At inference time, we want the expected prediction
from those $2^N$ models, so we scale each weights by $p$ Hinton et al

SRT injects noise on the feature space. In Bayesian NNs, the uncertainty 
comes from model parameters. It is easy to transform noise from features
to the model paramters. Suppose masks for features are $\epsilon_1, \epsilon_2$
and parameters are
$\theta = {M_1, M_2, b}$

Then, the model is equivalent to stochastic paramters
$\hat{\theta} = { diag(\epsilon_1)M_1, diag(\epsilon_2)M_2 } $

Then we can write the optimization objective as



with $\hat{W}^i_1$ and $\hat{W}^i_2$ corresponding to new masks $\hat{\epsilon}^i_1$
and $\hat{\epsilon}^i_2$ sampled for data point $i$.

For regression problem, minimizing MSL is equivalent to maximizing log 
likelihood


where $p(y| f^{M_1, M_2, b}(x)) = N(y; f^{M_1, M_2, b}(x), \tau^{-1}I) $

$\hat{w} = {\hat{W}^i_1, \hat{W}^i_2, b } =: g(\theta, \hat{\epsilon}_i)$ 
$p(\epsilon)$ is the product of Bernoulli distributions with probability
$p_i$ (the probability the neuron is not turned off).

So the loss objective is



This optimization objective is same to that of approximate inference
if in $\hat{L}_{MC}$ we choose the prior $p(w)$ in the way so that



If weights are trained with probability $p$, i.e. each weight has a 
probability $p$ to be turned on. Then, in the test time, we want
expected output of all those “thined network” therefore, we need to 
multiply each weights by $p$.

Optimising any neural network with dropout is equivalent to a form
of approximate inference in a probabilistic interpretation of the 
model.

Model uncertainty in Bayesian neural networks

variance ratio
predictive entropy
information gain

Some difficulties with measuring the uncertainty this way
Model’s uncertainty is not calibrated.

Reference
Grave, 2011, Practical Variational Inference for Neural Network

" />
    <meta property="og:description" content="Central theme:
Optimizing any deterministic NN with dropout is equivalent to 
a form of approximate inference in a probabilistic interpretation
of the model. This means the optimal weights found through the optimization
of a dropout NN are the same as the optimal variational parameters
in a Bayesian NN with the same structure.

Why do we call the paramters in a Bayesian NN a variational parameter?

want to find $q(w)$ that is close to the model’s posterior $p(w|X, Y)$ 
what is $\theta$ in relation to the weight parameters to Bayesian NN?

Techniques to estimate the expected log likelihood



Monte Carlo Estimator in variational inference

We wish to estimate the derivatives of the expected
log likelihood with respect to $\theta$. This allows
us to optimize the objective for the variational inference.

Consider in general



The score function estimator
Assume we can do differentiating outside integral side



This leads to an unbiased stochastic estimator



with $x \sim p_{\theta}(x)$, i.e. sample a few $x$ from 
$p_{\theta}(x)$, we can use it to estimate $I(\theta)$

Stochastic Regularizer

Dropout and Approximate Inference

To use the pathwise derivative estimator, we need to reparametrize each 
$q_{\theta_{l, i}}(w_{l,i})$ (The family of distributions on $w_{l, i}$
paramterized by $\theta_{l, i}$) as $w_{l,i} = g(\theta_{l,i}, \epsilon_{l,i})$
and specify some $p(\epsilon_{l,i})$.

The loss objective of variational inference is



Then we can replace the expected log likelihood with its stochastic 
estimator



such that 


  
    
      Therefore the SGD algorithm for minimizing  and $$p(w
      X, Y)$$
    
  



  Given dataset X, Y
Define learning rate $\eta$
Initialize parameters $\theta$ randomly


While $\theta$ has not converged

  
    Sample $M$ random variables $\hat{\epsilon}\sim p(\epsilon)$, $S$ a random 
subset of ${1, \dots, N}$ of size $M$
Calculate Stochastic derivative estimator w.r.t. $\theta$:
  





  
    Update $\theta$:
  




Let’s take a look at its relation with some stochastic regularization techniques.
The most popular SRT is dropout Suppose each input feature is used with 
probability $p$. Suppose the model has $N$ parameters, then dropout produces
$2^N$ ‘thinned’ networks. At inference time, we want the expected prediction
from those $2^N$ models, so we scale each weights by $p$ Hinton et al

SRT injects noise on the feature space. In Bayesian NNs, the uncertainty 
comes from model parameters. It is easy to transform noise from features
to the model paramters. Suppose masks for features are $\epsilon_1, \epsilon_2$
and parameters are
$\theta = {M_1, M_2, b}$

Then, the model is equivalent to stochastic paramters
$\hat{\theta} = { diag(\epsilon_1)M_1, diag(\epsilon_2)M_2 } $

Then we can write the optimization objective as



with $\hat{W}^i_1$ and $\hat{W}^i_2$ corresponding to new masks $\hat{\epsilon}^i_1$
and $\hat{\epsilon}^i_2$ sampled for data point $i$.

For regression problem, minimizing MSL is equivalent to maximizing log 
likelihood


where $p(y| f^{M_1, M_2, b}(x)) = N(y; f^{M_1, M_2, b}(x), \tau^{-1}I) $

$\hat{w} = {\hat{W}^i_1, \hat{W}^i_2, b } =: g(\theta, \hat{\epsilon}_i)$ 
$p(\epsilon)$ is the product of Bernoulli distributions with probability
$p_i$ (the probability the neuron is not turned off).

So the loss objective is



This optimization objective is same to that of approximate inference
if in $\hat{L}_{MC}$ we choose the prior $p(w)$ in the way so that



If weights are trained with probability $p$, i.e. each weight has a 
probability $p$ to be turned on. Then, in the test time, we want
expected output of all those “thined network” therefore, we need to 
multiply each weights by $p$.

Optimising any neural network with dropout is equivalent to a form
of approximate inference in a probabilistic interpretation of the 
model.

Model uncertainty in Bayesian neural networks

variance ratio
predictive entropy
information gain

Some difficulties with measuring the uncertainty this way
Model’s uncertainty is not calibrated.

Reference
Grave, 2011, Practical Variational Inference for Neural Network

" />
    
    <meta name="author" content="Stream of Conscious" />

    
    <meta property="og:title" content="Notes from Yarin Gal's Thesis" />
    <meta property="twitter:title" content="Notes from Yarin Gal's Thesis" />
    


<!--[if lt IE 9]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
    }
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>



<link rel="stylesheet" type="text/css" href="/style.css" />
<link rel="alternate" type="application/rss+xml" title="Stream of Conscious - " href="/feed.xml" />


    








<!-- Google Analytics -->
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-8161570-6', 'auto');
    ga('send', 'pageview');
</script>

<!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
</head>


  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Stream of Conscious</a></h1>
            <p class="site-description"></p>
          </div>

          <nav>
              <a href="/about"> About </a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Notes from Yarin Gal&#39;s Thesis</h1>
    <p class="post-meta">

      <time datetime="2020-05-23T09:06:08-07:00" itemprop="datePublished">
        
        May 23, 2020
      </time>

      <span itemprop="author" itemscope itemtype="http://schema.org/Person">
        by <span itemprop="name">Hongshan Li</span>
      </span>
        
      <span>[
      
    ]</span>

      <!--
      <span class="share-buttons">
        <span class="share-button"><a class="twitter-share-button" href="https://twitter.com/share" data-show-count="false">Tweet</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></span>

        <span class="share-button"><span class="fb-like" data-href="/example/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="false" data-share="true"></span></span>
      </span>
      <div style="clear: both;"/>
      -->

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Central theme:
Optimizing any deterministic NN with dropout is equivalent to 
a form of approximate inference in a probabilistic interpretation
of the model. This means the optimal weights found through the optimization
of a dropout NN are the same as the optimal variational parameters
in a Bayesian NN with the same structure.</p>

<p>Why do we call the paramters in a Bayesian NN a variational parameter?</p>

<p>want to find $q(w)$ that is close to the model’s posterior $p(w|X, Y)$ 
what is $\theta$ in relation to the weight parameters to Bayesian NN?</p>

<h2 id="techniques-to-estimate-the-expected-log-likelihood">Techniques to estimate the expected log likelihood</h2>

<script type="math/tex; mode=display">\int q_{\theta} \log p(y_i | f^w(x_i)) dw</script>

<h3 id="monte-carlo-estimator-in-variational-inference">Monte Carlo Estimator in variational inference</h3>

<p>We wish to estimate the derivatives of the expected
log likelihood with respect to $\theta$. This allows
us to optimize the objective for the variational inference.</p>

<p>Consider in general</p>

<script type="math/tex; mode=display">I(\theta) = \frac{\partial}{\partial\theta}
\int f(x) p_{\theta}(x) dx</script>

<h4 id="the-score-function-estimator">The score function estimator</h4>
<p>Assume we can do differentiating outside integral side</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\frac{\partial}{\partial\theta}
\int f(x) p_{\theta}(x) dx & = 
\int f(x) \frac{\partial}{\partial\theta} p_{\theta}(x) dx \\
& \int f(x) \frac{\partial \log p_{\theta}(x)}{\partial\theta} 
p_{\theta}(x) dx
\end{align} %]]></script>

<p>This leads to an unbiased stochastic estimator</p>

<script type="math/tex; mode=display">\hat{I}_1(\theta) = f(x)\frac{\partial \log p_{\theta}(x)}{\partial\theta}</script>

<p>with $x \sim p_{\theta}(x)$, i.e. sample a few $x$ from 
$p_{\theta}(x)$, we can use it to estimate $I(\theta)$</p>

<h2 id="stochastic-regularizer">Stochastic Regularizer</h2>

<h3 id="dropout-and-approximate-inference">Dropout and Approximate Inference</h3>

<p>To use the pathwise derivative estimator, we need to reparametrize each 
$q_{\theta_{l, i}}(w_{l,i})$ (The family of distributions on $w_{l, i}$
paramterized by $\theta_{l, i}$) as $w_{l,i} = g(\theta_{l,i}, \epsilon_{l,i})$
and specify some $p(\epsilon_{l,i})$.</p>

<p>The loss objective of variational inference is</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat{L}_{VI}(\theta) & = - C \sum_{i\in S} 
\int q_{\theta}(w) \log p(y_i | f^w(x_i)) dw + KL(q_{\theta}(w) || p(w))  \\
& = -C \sum_{i\in S} 
\int p(\epsilon)\log p(y_i|f^{g(\theta, \epsilon)}(x_i))d\epsilon 
+ KL(q_{\theta}(w) || p(w))
\end{align} %]]></script>

<p>Then we can replace the expected log likelihood with its stochastic 
estimator</p>

<script type="math/tex; mode=display">\hat{L}_{MC}(\theta) = -C \sum_{i \in S} \log p(y_i|f^{g(\theta,\epsilon)}(x_i)) 
+ KL(q_{\theta}(w) || p(w))</script>

<p>such that <script type="math/tex">\mathbb{E}_{S, \epsilon}(\hat{L}_{MC}(\theta)) = \hat{L}_{VI}(\theta)</script></p>

<table>
  <tbody>
    <tr>
      <td>Therefore the SGD algorithm for minimizing <script type="math/tex">q_{\theta}(w)</script> and $$p(w</td>
      <td>X, Y)$$</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Given dataset X, Y<br />
Define learning rate $\eta$<br />
Initialize parameters $\theta$ randomly<br /></p>
</blockquote>

<p>While $\theta$ has not converged</p>
<blockquote>
  <blockquote>
    <p>Sample $M$ random variables $\hat{\epsilon}\sim p(\epsilon)$, $S$ a random 
subset of ${1, \dots, N}$ of size $M$<br />
Calculate Stochastic derivative estimator w.r.t. $\theta$:</p>
  </blockquote>
</blockquote>

<script type="math/tex; mode=display">\hat{\Delta\theta} \leftarrow -\frac{N}{M} \sum_{i\in S} 
\frac{\partial}{\partial\theta} \log p(y_i | f^{g(\theta, \epsilon)}) 
+ \frac{\partial}{\partial\theta} KL(q_{\theta}(w) || p(w))</script>

<blockquote>
  <blockquote>
    <p>Update $\theta$:</p>
  </blockquote>
</blockquote>

<script type="math/tex; mode=display">\theta \leftarrow \theta + \eta \hat{\Delta\theta}</script>

<p>Let’s take a look at its relation with some stochastic regularization techniques.
The most popular SRT is <em>dropout</em> Suppose each input feature is used with 
probability $p$. Suppose the model has $N$ parameters, then dropout produces
$2^N$ ‘thinned’ networks. At inference time, we want the expected prediction
from those $2^N$ models, so we scale each weights by $p$ <a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Hinton et al</a></p>

<p>SRT injects noise on the feature space. In Bayesian NNs, the uncertainty 
comes from model parameters. It is easy to transform noise from features
to the model paramters. Suppose masks for features are $\epsilon_1, \epsilon_2$
and parameters are
$\theta = {M_1, M_2, b}$</p>

<p>Then, the model is equivalent to stochastic paramters
$\hat{\theta} = { diag(\epsilon_1)M_1, diag(\epsilon_2)M_2 } $</p>

<p>Then we can write the optimization objective as</p>

<script type="math/tex; mode=display">\hat{L}_{dropout}(M_1, M_2, b) := 
\frac{1}{M} \sum_{i\in S} E^{\hat{W}^i_1, \hat{W}^i_2, b}(x_i, y_i) 
    + \lambda_1 ||M_1||^2 + \lambda_2 ||M_2||^2 + \lambda_3||b||^2</script>

<p>with $\hat{W}^i_1$ and $\hat{W}^i_2$ corresponding to new masks $\hat{\epsilon}^i_1$
and $\hat{\epsilon}^i_2$ sampled for data point $i$.</p>

<p>For regression problem, minimizing MSL is equivalent to maximizing log 
likelihood</p>

<p><script type="math/tex">\log p(y|f^{M_1, M2, b}(x)) + \text{const}</script>
where $p(y| f^{M_1, M_2, b}(x)) = N(y; f^{M_1, M_2, b}(x), \tau^{-1}I) $</p>

<p>$\hat{w} = {\hat{W}^i_1, \hat{W}^i_2, b } =: g(\theta, \hat{\epsilon}_i)$ 
$p(\epsilon)$ is the product of Bernoulli distributions with probability
$p_i$ (the probability the neuron is not turned off).</p>

<p>So the loss objective is</p>

<script type="math/tex; mode=display">\hat{L}_{dropout}(M_1, M_2, b) = -\frac{1}{M_{\tau}} 
\sum_{i \in S} \log p(y_i | f^g(x)) + \lambda_1||M_1||^2 
+ \lambda_2 ||M_2||^2 + \lambda_3||b||^2</script>

<p>This optimization objective is same to that of approximate inference
if in $\hat{L}_{MC}$ we choose the prior $p(w)$ in the way so that</p>

<script type="math/tex; mode=display">KL(q_{\theta}(w) || p(w)) \propto \lambda_1||M_1||^2 + \lambda_2||M_2||^2 
+ \lambda_3||b||^2</script>

<p>If weights are trained with probability $p$, i.e. each weight has a 
probability $p$ to be turned on. Then, in the test time, we want
expected output of all those “thined network” therefore, we need to 
multiply each weights by $p$.</p>

<p>Optimising any neural network with dropout is equivalent to a form
of approximate inference in a probabilistic interpretation of the 
model.</p>

<h2 id="model-uncertainty-in-bayesian-neural-networks">Model uncertainty in Bayesian neural networks</h2>

<p>variance ratio
predictive entropy
information gain</p>

<h3 id="some-difficulties-with-measuring-the-uncertainty-this-way">Some difficulties with measuring the uncertainty this way</h3>
<p>Model’s uncertainty is not calibrated.</p>

<h1 id="reference">Reference</h1>
<p><a href="https://papers.nips.cc/paper/4329-practical-variational-inference-for-neural-networks.pdf">Grave, 2011, Practical Variational Inference for Neural Network</a></p>


  </div>


  <div class="page-navigation">
    
      <a class="prev" href="/bayesian-deep-learning/">&larr; Overview of Bayesian deep learning</a>
    

    
  </div>

  

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          <!--   
<div style="clear: both;"/>
<footer class="site-footer">
    <p>
    Add stuff to footer
    </p>
</footer>
 -->
        </footer>
      </div>
    </div>
  </body>
</html>
