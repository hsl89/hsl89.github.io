I"£3<blockquote>
  <p>As we have seen from the <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a>. The probability vector of
a deterministic network cannot consistently captures the uncertainty of its
prediction. And we also see that if we use the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics and using it to study the model uncertainty. Then we will use 
this uncertainty to design an active learning query strategy.</p>
</blockquote>

<h2 id="warm-up">Warm up</h2>
<p>In supervised machine learning, the objective is to find a function
$f$ that best describes the features $X = (x_1, x_2, \cdots, x_n)$
and the labels $Y = (y_1, y_2, \cdots, y_n)$. Suppose the data 
$D = (X, Y)$ is observed from the system $S$. Then, $f$ is a proxy
to the real data generation process of $S$ which is difficult to know.
The criterion for a good model $f$ is that when new observations 
$D^{\prime} = (X^{\prime}, Y^{\prime}$ arises, $f$ can still relate
$X^{\prime}$ and $Y^{\prime}$ with good precision.</p>

<p>Let take one step back and think about what are we doing when we build
and train an ML model?
There are infinitely many ways you can relate $X$ to $Y$ up to certain extent, 
the process of building and training an ML model is amount to find an $f$
such that <em>after</em> seeing the data $D$, we belief $f$ is the most likely 
candidate that describe the unknown data generation process of $S$.</p>

<p>Formally, let $\Theta$ be the function space that describes the process of 
$S$ that relates $X$ to $Y$, i.e. $\Theta$ is a set of all <em>possible</em> candidates
$\theta$ that relates $X$ to $Y$. The process of machine learning is to 
find a conditional distribution $p(\theta | D)$ over $\Theta$. This distribution
reflects our belief on how likely the candidate $\theta$ is the one that relates
$X$ to $Y$. This distribution $p(\theta | D)$ has an interesting name, it is called
the <em>posterior</em> distribution on $\Theta$, because it is something we derive <em>after</em>
seeing $D$.</p>

<p>This brings us to the playground of Bayesian statistics, because it offers a 
framework for us to think about $p(\theta | D)$.</p>

<h2 id="bayes-theorem">Bayes‚Äô Theorem</h2>
<p>There are two things you can do when you are handed with the data $D$:</p>

<p>1) Based on your understanding of the $S$, you make a hypothesis $H$ about the 
how $X$ and $Y$ are related, then you update your hypothesis $H$ after
inspecting $D$</p>

<p>2) You can compute frequency statistics on $D$ and make claims on $S$ 
directly from those frequency statistics. For example, you might have
heard people talking about making <em>Null Hypothesis</em> and calculating
$p$-value that reflects the probability that <strong>given</strong> Null Hypothesis
is true, Null Hypothesis would be rejected $p*100$ times out of 100 trials 
due to randomness in data collection.</p>

<p>If you prefer 1, then you are labeled as a <em>Bayesian statistician</em>;
If you prefer 2, then you are labeled as a <em>frequentist</em></p>

<p>The subtle difference between Bayesians and frequentists is that 
Bayesians want $P(H | D)$ whereas frequentists want $P(D | H)$, i.e.
Bayesians want to know how much belief to put in the hypothesis 
$H$ after seeing the data $D$; frequentists want to know given the 
hypothesis is true, what‚Äôs the odd for the observation $D$?</p>

<p>One thing that relates these two schools of thought is the Bayes‚Äô Theorem:</p>

<script type="math/tex; mode=display">P(H | D) = \frac{P(D | H) P(H)}{P(D)}</script>

<p>In Bayesian statistics, each term above has a name:</p>

<p>$P(D | H)$ is the <em>likelyhood</em> of the dataset $D$,i.e.
how likely can we see $D$ given hypothesis $H$</p>

<p>$P(H)$ is the <em>prior</em> on the hypothesis $H$,i.e. how
deep we believe the data generation process is $H$.</p>

<p>$P(D)$ is called the <em>evidence</em>. It is the probablity of the 
observation $D$. One way to think about it is ‚Äúthe average‚Äù 
probability of seeing the observation $D$ over all hypothesis
of data generation process:</p>

<script type="math/tex; mode=display">P(D) = \int P(D | H) P(H) dH</script>

<p>If you do machine learning, then you are baptized by Bayesian
school of thought, even if you have not heard of Bayesian statistics
until 10 mins ago. When you do the following things</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sklearn.ensembles import RandomForestClassifier
</code></pre></div></div>
<p>or</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch.nn as nn
</code></pre></div></div>
<p>you are conjuring up a hypothesis $H$ about the relation between $X$ and $Y$,
a function space $\Theta$ that describes the relation between $X$ and $Y$ and
a <em>prior</em> probability distribution $p(\theta)$ on $\Theta$. Except intead of
looking at all possible functions, you are looking at functions that look like
a random forest in case 1, a neural network in case 2.</p>

<p>When you train your model, you are updating your posterior $P(\theta | D)$ on 
$\Theta$. Each ‚Äúfit‚Äù you do gives you the most likely candidate $\theta$ given $D$.</p>

<h2 id="uncertainty">Uncertainty</h2>
<p>Before we jump into uncertainty in machine learning, let‚Äôs ask ourselves what are
we even uncertain about? (Pause and think)</p>

<p>I think one reasonable thing to be uncertain about is the posterior distribution
$p(\theta | D)$ on $\Theta$. We find a posterior through marvelous machine learning,
how do we know how far it is from the true posterior?</p>

<p>You can ‚Äúcompute‚Äù this uncertainty via Shannon entropy:</p>

<script type="math/tex; mode=display">H[\theta | D] = -\int_{\Theta} p(\theta | D) \log p(\theta | D) d\theta</script>

<p>The uncertainty on the posterior $p(\theta | D)$ naturally carries over 
to the uncertainty for making predictions. Let $x^*$ be a new sample
observed from the system $S$.</p>

<p>Given our function space $\Theta$ and 
posterior $p(\theta | D)$, the probability of $x^*$ mapped to $y^*=c$
under the unknown data generation process of $S$ is given by</p>

<script type="math/tex; mode=display">p(y^*=c | x^*, D) = \int_{\Theta} p(y^*=c | x^*, \theta)p(\theta | D) d\theta</script>

<p>If the output $y^*$ is a discrete random variable that takes on value
$c_1, c_2, \cdots, c_n$, then we can again use Shannon entropy to 
‚Äúcompute‚Äù this predictive uncertainty</p>

<script type="math/tex; mode=display">H[y^*|x^*, D] = - \sum_{i=1}^n p(y^*=c_i | x^*, D)\log p(y^*=c_i | x^*, D)</script>

<h2 id="information-theoretic-active-learning">Information-theoretic active learning</h2>
<p>The goal of active learning is to selectively add data to the training 
set $D$ that ‚Äúboost the model‚Äôs performance to the largest extent‚Äù. 
In light of the Bayesian philosophy, how do we materialize the objective of 
active learning?</p>

<p>One reasonable thing we can do is to enlarge the data set $D$ in the way
so that it reduces the uncertainty of posterior $p(\theta | D)$ fastest.
We assumed the existence of a function space $\Theta$ that gathers all potential
candidates for describing the data generation process of $S$, we have computed
the posterior $p(\theta | D)$ on $\Theta$. Now, we are given more data $D^{\prime}$
we can say the most valuable sample $(x‚Äô, y‚Äô)$ is the one that reduces the 
uncertainty of the posterior $p(\theta | D \cup {(x‚Äô, y‚Äô)})$ fastest, i.e.</p>

<script type="math/tex; mode=display">\text{arg max}_{x',y'} H[\theta | D] - \mathbb{E}_{y'\sim p(y'|x',D)}</script>

<script type="math/tex; mode=display">\text{arg max}_{x} H[y|x, D] - E_{\theta \sim p(\theta | D)}[H[y|x, \theta]]</script>

<h2 id="bayesian-machine-learning">Bayesian Machine Learning</h2>
<p>What is the uncertainty of a machine learning model? A machine learning
model describes a data generation process. This process is hypthesized 
by machines learning scientists. The uncertainty of the model really means
the uncertainty on the hypothesis $\mathcal{H}$ about the data generation
process which lead to the definition of the model.</p>

<p>Therefore, when talking about the uncertainty of the model, we are computing
the probability of the hypothesis $\mathcal{H}$ based on observed data 
$\mathcal{D}$</p>

<script type="math/tex; mode=display">P(\mathcal{H} | \mathcal{D})</script>

<p>This is called the <em>posterior</em> probability on $\mathcal{H}$, because it is 
something we evaluate <em>after</em> seeing the data. According to Bayes rule, 
we can compute the posterior by</p>

<script type="math/tex; mode=display">P(\mathcal{H} | \mathcal{D}) = \frac{P(\mathcal{D} | \mathcal{H})
    P(\mathcal{H})}{P(\mathcal{D})}</script>

<p>Let break down the formula:</p>

<p>$P(\mathcal{D} | \mathcal{H})$ is the <em>likelyhood</em> of the dataset $D$,i.e.
how likely can we see this dataset $D$ if the data generation process is
indeed $\math{H}$</p>

<p>$P(\mathcal{H})$ is the <em>prior</em> on the hypothesis $\mathcal{H}$,i.e. how
deep we believe the data generation process is $\mathcal{H}$.</p>

<p>$P(\mathcal{D})$ is called the <em>evidence</em>. It is the probablity of the 
observation $\mathcal{D}$. One way to think about it is ‚Äúthe average‚Äù 
probability of seeing the observation $\mathcal{D}$ over all hypothesis
of data generation process</p>

<script type="math/tex; mode=display">P(\mathcal{D}) = \int P(\mathcal{D} | \mathcal{H}) P(\mathcal{H}) d\mathcal{H}</script>

<p>Need to define the model in the way so that $P(\mathcal{H})$? 
That why for a Bayesian network, each neuron is a probability distribution
rather than a deterministic number.</p>

<h2 id="source-of-uncertainty">Source of uncertainty</h2>
<p>From model
large number of possible models can explain the dataset</p>

<p>From data
Training labels are noisy
The synthetic data in my <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a> has this type of uncertainty.</p>

<h2 id="how-to-bayesianify">How to Bayesianify</h2>

<p>Inference</p>

<script type="math/tex; mode=display">P(y=c |x^*, D) = \int p(y=c|x, w)p(w | D) dw</script>

<p>Why do we want uncertain data in the inference to train the model? 
It looks like the uncertainty is independent of the model itself?</p>

<p>Evidence that Bayesian deep model gives a better notion of uncertainty</p>

<h2 id="information-theoretic-active-learning-1">Information-theoretic active learning</h2>
<p>Latent parameters $\theta$ (weights of a deep nn) that controls the dependence
between inputs X and output Y: $p(Y | X, \theta)$</p>

<table>
  <tbody>
    <tr>
      <td>When data $D$ is observed, posterior $p(\theta</td>
      <td>D)$ is computed.</td>
    </tr>
  </tbody>
</table>

<p>Okay, data generation process can be thought as a function space $\Theta$</p>

<script type="math/tex; mode=display">\text{arg min}_{D^'} =
H[\theta | D^'] = -\int_{\Theta} p(\theta | D^')\log p(\theta | D^') d\theta</script>

<p>Even we find this dataset $D‚Äô$, why it helps learning? i.e. why it improves 
generalization error? Almost by definition, higher posterior means you are more
certain the data generation process $\Theta$ is the true underlying process
that relatex X to Y, i.e. better model.</p>

<p>Okay, so the prior belief of data generation process is a function space $\Theta$
together with a distribution $P(\Theta)$, such that each $p(\theta)$ indicates our
prior belief that X and Y are related by $\theta$.</p>

<p>Goal is to find a dataset $D$ that changes the posterior $p(\theta | D)$ so that 
we have better confidence on where we should sample $\theta$ from the function 
space $\Theta$ so that it most correctly describes the relation X and Y. Uncertainty
of a distribution can be computed as</p>

<script type="math/tex; mode=display">shannon entropy</script>

<p>Therefore, the goal is to find data that reduces the uncertainty fastest.</p>

<script type="math/tex; mode=display">\text{arg max}_{x} H[\theta | D] - E[H(\theta | y, x, D)]</script>

<p>It is equivalent to the conditional information gain</p>

<script type="math/tex; mode=display">\text{arg max}_{x} H[y|x, D] - E_{\theta \sim p(\theta | D)}[H[y|x, \theta]]</script>

<p>We seek $x$ for which the model is marginally most uncertainty about $y$
(high $H[y|x, D]$).
but for which individual settings of the parameters are confident 
(low $H[y|x, \theta]$). 
This can be interpreted as seeking $x$ for which the parameters under posterior
(trained) disagree about the output most. Refer this as BALD</p>

<h2 id="reference">Reference</h2>
<p>comparison between bayesian and frequentist
https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading20.pdf</p>

<p><a href="http://mlg.eng.cam.ac.uk/yarin/thesis/3_bayesian_deep_learning.pdf">Yarin Gal Thesis</a></p>

<p>https://www.mit.edu/~9.520/spring11/slides/class19_approxinf.pdf</p>

<p>Image data
https://arxiv.org/pdf/1703.02910.pdf</p>

<p>Classification
https://arxiv.org/pdf/1112.5745.pdf</p>

:ET