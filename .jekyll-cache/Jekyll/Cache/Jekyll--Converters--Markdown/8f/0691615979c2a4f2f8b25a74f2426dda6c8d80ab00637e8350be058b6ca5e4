I"y<blockquote>
  <p>As we have seen from the <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a>. The probability vector of
a deterministic network cannot consistently captures the uncertainty of its
prediction. And we also see that using the entropy of the probablity 
vector as a proxy to uncertainty, the performance of active learning is 
pretty bad. In this post, I want to discuss some basics of Bayesian 
statistics. It is systematic framework to study and evaluate uncertainty
of a system. Then, I want to show you how to bayesianify a deep learning 
model so that it yields a more consistent notion of uncertainty.</p>
</blockquote>

<h2 id="warm-up">Warm up</h2>
<p>Machine learning boils down to statistical inference:
Given a set of <em>known</em>, make claims on <em>unknown</em></p>

<p>There are two ways to look at the <em>known</em></p>

<p>1) Based on your understanding of the <em>world</em> make a hypothesis about the 
system where the <em>known</em> is collected, then use the <em>known</em> to evaluate
your hypothesis.</p>

<p>2) Make claims about the system directly based on the observed <em>knwon</em></p>

<p>If you prefer 1, then you are labeled as a <em>Bayesian people</em>;
If you prefer 2, then you are labeled as a <em>frequentist</em></p>

<h2 id="notations">Notations</h2>

<h2 id="bayesian-machine-learning">Bayesian Machine Learning</h2>
<p>What is the uncertainty of a machine learning model? A machine learning
model describes a data generation process. This process is hypthesized 
by machines learning scientists. The uncertainty of the model really means
the uncertainty on the hypothesis $\mathcal{H}$ about the data generation
process which lead to the definition of the model.</p>

<p>Therefore, when talking about the uncertainty of the model, we are computing
the probability of the hypothesis $\mathcal{H}$ based on observed data 
$\mathcal{D}$</p>

<script type="math/tex; mode=display">P(\mathcal{H} | \mathcal{D})</script>

<p>This is called the <em>posterior</em> probability on $\mathcal{H}$, because it is 
something we evaluate <em>after</em> seeing the data. According to Bayes rule, 
we can compute the posterior by</p>

<script type="math/tex; mode=display">P(\mathcal{H} | \mathcal{D}) = \frac{P(\mathcal{D} | \mathcal{H})
    P(\mathcal{H})}{P(\mathcal{D})}</script>

<p>Let break down the formula:</p>

<p>$P(\mathcal{D} | \mathcal{H})$ is the <em>likelyhood</em> of the dataset $D$,i.e.
how likely can we see this dataset $D$ if the data generation process is
indeed $\math{H}$</p>

<p>$P(\mathcal{H})$ is the <em>prior</em> on the hypothesis $\mathcal{H}$,i.e. how
deep we believe the data generation process is $\mathcal{H}$.</p>

<p>$P(\mathcal{D})$ is called the <em>evidence</em>. It is the probablity of the 
observation $\mathcal{D}$. One way to think about it is “the average” 
probability of seeing the observation $\mathcal{D}$ over all hypothesis
of data generation process</p>

<script type="math/tex; mode=display">P(\mathcal{D}) = \int P(\mathcal{D} | \mathcal{H}) P(\mathcal{H}) d\mathcal{H}</script>

<p>Need to define the model in the way so that $P(\mathcal{H})$? 
That why for a Bayesian network, each neuron is a probability distribution
rather than a deterministic number.</p>

<h2 id="source-of-uncertainty">Source of uncertainty</h2>
<p>From model
large number of possible models can explain the dataset</p>

<p>From data
Training labels are noisy
The synthetic data in my <a href="https://hsl89.github.io/uncertainty-of-deep-neural-network/">previous post</a> has this type of uncertainty.</p>

<h2 id="how-to-bayesianify">How to Bayesianify</h2>

<p>Inference</p>

<script type="math/tex; mode=display">P(y=c |x^*, D) = \int p(y=c|x, w)p(w | D) dw</script>

<p>Why do we want uncertain data in the inference to train the model? 
It looks like the uncertainty is independent of the model itself?</p>

<p>Evidence that Bayesian deep model gives a better notion of uncertainty</p>

<h2 id="reference">Reference</h2>
<p><a href="http://mlg.eng.cam.ac.uk/yarin/thesis/3_bayesian_deep_learning.pdf">Yarin Gal Thesis</a></p>

<p>https://www.mit.edu/~9.520/spring11/slides/class19_approxinf.pdf</p>
:ET